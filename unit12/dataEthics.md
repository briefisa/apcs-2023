## Data Ethics

Data is a slippery slope; it's essential to our technology-fueled civilization and online lifestyle, yet once you start collecting individuals’ data it can quickly spiral out of hand. 
For example, apparently my school Google account has a shocking 116 passwords saved or linked to it, which is a testament both to the amount of data Google stores and the number of 
websites that require users to set up accounts (likely in order to collect their users’ data more effectively). 

Surrounding this extensive collection of data, I’m most interested in the balance between  user confidentiality on the one hand and actually relevant, efficient web results on the other.
With the vast amount of information on the internet - and the majority of it a useless mess - it is impossible to not collect a huge amount of data on websites themselves (and what 
keywords, information, media, and links they contain). Without this data and efficient search engines, it would be impossible to find anything useful online. 

However, the area starts to become more gray when companies start collecting user data. A large part of this issue is that companies are incentivized to collect as much data about their 
users as possible; the more you know about a user’s preferences, hobbies, demographics, social background, habits, etc. etc., the more effective your recommendations to them will be (both
regarding content and ads), therefore the more time they’ll spend online, the more ads you can show them, and the more revenue for Google. Furthermore, according to the CDC, teens now 
spend an average of over 7 hours a day on screens (https://www.cdc.gov/nccdphp/dnpao/mult imedia/infographics/getmoving.html). When you account for sleep, that’s creeping up towards 50 
percent of our day spent online. With so much of our time and attention transitioning from the physical world to the digital, it’s clear why companies are so intent on profiting from our 
time online, and most frequently this comes not through taking our money, but taking our privacy. Solving this problem so that the internet prioritizes user privacy is so difficult because 
it would require a fundamental restructuring of how the companies that run the internet (like Google, Amazon, and Microsoft) make their money.

Another relevant issue related to data collection is the addictiveness of technology. As I mentioned, companies are monetarily incentivized to collect lots of data on their users, and this 
is especially true for entertainment platforms like tiktok, instagram, and youtube. These companies rely on data so that they can make the best recommendations to their users in order to 
keep them on the internet longer and therefore show them more ads. However, I think that most people (especially high schoolers) would agree that they spend far too much time wasting time 
on sites like these every day, in large part due to how addictive entertainment platforms have become. At a certain point, a recommendation algorithm (and the data it relies on) goes from 
being a useful tool to show users things they might be interested in, to a parasite whose only purpose is to be as addictive as possible. This conflict of interest between tech companies 
and their users is central to the debate surrounding how much data companies should really be collecting.

Ultimately, I think that it’s impossible to have it all; I can’t really imagine companies voluntarily giving up their user data to ensure privacy, but at the same time, if we write laws to 
severely limit and regulate data collection, it will be much harder to receive the accurate, entertaining online content and personalized suggestions that many of us have come to expect. In
the end, the debate around data is just a part of the larger discussion surrounding what the human relationship to technology should look like, a discussion that has become even more
important with the widespread use of AI and our continually increasing use of technology.